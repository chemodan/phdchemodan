{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing together GDP and Personal Income by US County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from sklearn import decomposition\n",
    "import statsmodels.regression.linear_model as lm\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "MYDIR = \"./../../ResearchProposal/\"\n",
    "\n",
    "# print(os.path)\n",
    "myFiles = os.listdir(MYDIR)\n",
    "# print(myFiles)\n",
    "\n",
    "gdpFile = MYDIR + \"bea_gov/gdp/gdp_ready_to_analyze.csv\"\n",
    "piFile = MYDIR + \"bea_gov/personal_income/personal_income_ready_to_analyze.csv\"\n",
    "hhiFile = MYDIR + \"income_inequality/census_income_by_county/hh_income__census_data.csv\"\n",
    "populationFile = MYDIR + \"population_dynamics/census_population_data_2010_2019.csv\"\n",
    "suicideFile = MYDIR + \"suicide/multiple_causes_of_death__suicide.csv\"\n",
    "employmentFile = MYDIR + \"unemployment/employment_by_county_state_year.csv\"\n",
    "stateAbbrevFile = MYDIR + \"state_abbreviations.csv\"\n",
    "myfiles = {\"gdp\": gdpFile,\n",
    "           \"pi\": piFile,\n",
    "           \"hhi\": hhiFile,\n",
    "           \"pop\": populationFile,\n",
    "           \"sc\": suicideFile,\n",
    "           \"emp\": employmentFile,\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mobilityHelpers:\n",
    "    def __init__(self, \n",
    "                 myFiles: Dict[str, str] = myfiles,\n",
    "                 ctv_cutoff: float = 0.055):\n",
    "        self.mCTVcutoff = ctv_cutoff\n",
    "        self.mFiles = myfiles\n",
    "        \n",
    "        self.mStateAbbreviationsDF = pd.read_csv(stateAbbrevFile)\n",
    "        \n",
    "    \n",
    "    def getPopulationDynamicsData(self, verbose: bool = False) -> Tuple[pd.DataFrame]:\n",
    "        \n",
    "        popDFraw = pd.read_csv(self.mFiles[\"pop\"], encoding = \"ISO-8859-1\")\n",
    "        cols = list(popDFraw.columns)\n",
    "        cols2keep = [cc for cc in cols if \\\n",
    "                          (cc not in (\"SUMLEV\", \"REGION\", \"DIVISION\", \"STATE\", \"COUNTY\")) and \\\n",
    "                          ('GQESTIMATE' not in cc) and \\\n",
    "                          ('RESIDUAL' not in cc)]\n",
    "        cols2keep\n",
    "        popDFraw = popDFraw[cols2keep].copy()\n",
    "        popDF = popDFraw[popDFraw[\"CTYNAME\"] != popDFraw[\"STNAME\"]].copy()\n",
    "        popDF[\"county\"] = popDF[\"CTYNAME\"].str.replace(\" County\", \"\")\n",
    "        popDF[\"county_state\"] = popDF[\"county\"] + \", \" + popDF[\"STNAME\"]\n",
    "        popDF.rename(columns={\"STNAME\": \"state\"}, inplace=True)\n",
    "        del popDF[\"CTYNAME\"]\n",
    "\n",
    "        popDFlong = self.meltAndReplaceYear(popDF, \n",
    "                                            [\"state\", \"county\", \"county_state\"],\n",
    "                                            verbose=verbose\n",
    "                                           )\n",
    "                                           \n",
    "        return popDF, popDFlong\n",
    "    \n",
    "    def getEmpData(self, verbose: bool = False) -> Tuple[pd.DataFrame]:\n",
    "        if verbose:\n",
    "            print(f\"\"\"Getting employment data from {employmentFile}\"\"\")\n",
    "        empDFRaw = pd.read_csv(employmentFile)\n",
    "        empDFRaw[[\"county\", \"st\"]] = empDFRaw[\"county_state\"].str.split(\", \", \n",
    "                                                                        expand=True)\n",
    "        \n",
    "        empDFRaw.rename(columns={\"county_state\": \"county_st\"}, inplace=True)\n",
    "        empDF = empDFRaw.merge(self.mStateAbbreviationsDF, on=\"st\")\n",
    "\n",
    "        empDF[\"county_state\"] = empDF[\"county\"] + \", \" + empDF[\"state\"]\n",
    "        del empDF[\"county_st\"]\n",
    "        del empDF[\"st\"]\n",
    "        \n",
    "        empDFlong = empDF.melt(id_vars=[\"county\", \"state\", \"county_state\", \"year\"])\n",
    "        empDFlong.rename(columns={\"variable\": \"metric\"}, inplace=True)\n",
    "        \n",
    "        empDFlong[\"metric\"] = empDFlong.metric.str.upper()\n",
    "\n",
    "        empDFlong[\"year\"] = empDFlong[\"year\"].astype(\"int64\")\n",
    "        \n",
    "        return empDF, empDFlong\n",
    "    \n",
    "    def getGDPdata(self, verbose: bool = False) -> Tuple[pd.DataFrame]:\n",
    "        gdpDFraw = pd.read_csv(gdpFile)\n",
    "        cols = list(gdpDFraw.columns)\n",
    "        for ii in range(len(gdpDFraw.columns)):\n",
    "            cc = cols[ii]\n",
    "            cols[ii] = cc.replace(\"real_gdp_2012usd_\", \"gdp\")\n",
    "        gdpDFraw.columns = cols\n",
    "        gdpDF = gdpDFraw[gdpDFraw[\"aggregation_level\"] != gdpDFraw[\"state\"]]\n",
    "        \n",
    "        gdpDFlong = self.meltAndReplaceYear(gdpDF,\n",
    "                                            idVars=[\"aggregation_level\", \"state\"],\n",
    "                                            verbose=verbose\n",
    "                                           )\n",
    "        gdpDFlong.rename(columns={\"aggregation_level\": \"county\"}, inplace=True)\n",
    "        gdpDFlong[\"county_state\"] = gdpDFlong[\"county\"] + \", \" + gdpDFlong[\"state\"]\n",
    "        gdpDFlong[\"metric\"] = gdpDFlong[\"metric\"].str.upper()\n",
    "        \n",
    "        return gdpDF, gdpDFlong\n",
    "    \n",
    "    def getHouseholdIncomeData(self) -> Tuple[pd.DataFrame]:\n",
    "        hhiDF = pd.read_csv(hhiFile)[[\"county\", \"state\", \"county_state\", \"year\",\n",
    "                              \"mean_to_median_household_income_ratio\",\n",
    "                              \"Median_income__dollars\", \"Mean_income__dollars\"]]\n",
    "        hhiDF.columns = [cc.lower() for cc in hhiDF.columns]\n",
    "        \n",
    "        hhiDFlong = self.meltAndReplaceYear(hhiDF, [\"county\", \"state\", \"county_state\", \"year\"])\n",
    "        \n",
    "        hhiDFlong[\"year\"] = hhiDFlong[\"year\"].astype(\"int64\")\n",
    "        return hhiDF, hhiDFlong\n",
    "    \n",
    "    def getSuicideRateData(self) -> Tuple[pd.DataFrame]:\n",
    "        \n",
    "        scDF = pd.read_csv(suicideFile)[[\"state\", \"county\", \"county_state\", \"year\",\n",
    "                                         \"age_adjusted_rate\", \"population\", \"deaths\", \"death_rate\"]]\n",
    "        scDF.columns = [cc.lower() for cc in scDF.columns]\n",
    "        scDF.rename(columns={\"age_adjusted_rate\": \"SCRATE\"}, inplace=True)\n",
    "        scDF.rename(columns={\"population\": \"POP_CDC\"}, inplace=True)\n",
    "        scDF.rename(columns={\"deaths\": \"SCDEATHS\"}, inplace=True)\n",
    "        scDF.rename(columns={\"death_rate\": \"SC_R_DEATH\"}, inplace=True)\n",
    "        scDFlong = scDF.melt(id_vars=[\"county\", \"state\", \"county_state\", \"year\"])\n",
    "        \n",
    "        scDFlong.rename(columns={\"variable\": \"metric\"}, inplace=True)\n",
    "\n",
    "        scDFlong[\"year\"] = scDFlong[\"year\"].astype(\"int64\")\n",
    "        \n",
    "        return scDF, scDFlong\n",
    "    \n",
    "    \n",
    "    def meltAndReplaceYear(self, \n",
    "                           myDF: pd.DataFrame,\n",
    "                           idVars: List[str],\n",
    "                           verbose: bool = False,\n",
    "                          ) -> pd.DataFrame:\n",
    "        \n",
    "        myDFlong = myDF.melt(id_vars = idVars)\n",
    "        if verbose:\n",
    "            print(myDFlong.head())\n",
    "\n",
    "        if \"year\" not in idVars:\n",
    "            myDFlong[\"year\"] = myDFlong[\"variable\"].str.replace(\"\\D+\", \"\").astype(\"int64\")\n",
    "        \n",
    "        myDFlong[\"metric\"] = myDFlong[\"variable\"].str.replace(\"\\d+\", \"\")\n",
    "\n",
    "        del myDFlong[\"variable\"]\n",
    "    \n",
    "        return myDFlong  \n",
    "\n",
    "    \"\"\"Copied from https://stackoverflow.com/questions/7404116/defining-the-midpoint-of-a-colormap-in-matplotlib\"\"\"\n",
    "    def shiftedColorMap(self, cmap, \n",
    "                        start=0, midpoint=0.5, stop=1.0, name='shiftedcmap'):\n",
    "        '''\n",
    "        Function to offset the \"center\" of a colormap. Useful for\n",
    "        data with a negative min and positive max and you want the\n",
    "        middle of the colormap's dynamic range to be at zero.\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "          cmap : The matplotlib colormap to be altered\n",
    "          start : Offset from lowest point in the colormap's range.\n",
    "              Defaults to 0.0 (no lower offset). Should be between\n",
    "              0.0 and `midpoint`.\n",
    "          midpoint : The new center of the colormap. Defaults to \n",
    "              0.5 (no shift). Should be between 0.0 and 1.0. In\n",
    "              general, this should be  1 - vmax / (vmax + abs(vmin))\n",
    "              For example if your data range from -15.0 to +5.0 and\n",
    "              you want the center of the colormap at 0.0, `midpoint`\n",
    "              should be set to  1 - 5/(5 + 15)) or 0.75\n",
    "          stop : Offset from highest point in the colormap's range.\n",
    "              Defaults to 1.0 (no upper offset). Should be between\n",
    "              `midpoint` and 1.0.\n",
    "        '''\n",
    "        cdict = {\n",
    "            'red': [],\n",
    "            'green': [],\n",
    "            'blue': [],\n",
    "            'alpha': []\n",
    "        }\n",
    "\n",
    "        # regular index to compute the colors\n",
    "        reg_index = np.linspace(start, stop, 257)\n",
    "\n",
    "        # shifted index to match the data\n",
    "        shift_index = np.hstack([\n",
    "            np.linspace(0.0, midpoint, 128, endpoint=False), \n",
    "            np.linspace(midpoint, 1.0, 129, endpoint=True)\n",
    "        ])\n",
    "\n",
    "        for ri, si in zip(reg_index, shift_index):\n",
    "            r, g, b, a = cmap(ri)\n",
    "\n",
    "            cdict['red'].append((si, r, r))\n",
    "            cdict['green'].append((si, g, g))\n",
    "            cdict['blue'].append((si, b, b))\n",
    "            cdict['alpha'].append((si, a, a))\n",
    "\n",
    "        newcmap = matplotlib.colors.LinearSegmentedColormap(name, cdict)\n",
    "        plt.register_cmap(cmap=newcmap)\n",
    "\n",
    "        return newcmap\n",
    "    \n",
    "    def plotCorrMatrix(self, myDF: pd.DataFrame, title: str, method: str = \"pearson\"):\n",
    "        f = plt.figure(figsize=(15, 12))\n",
    "        orig_cmap = matplotlib.cm.PuOr\n",
    "        shifted_cmap = self.shiftedColorMap(orig_cmap, \n",
    "                                       start=-1.0,\n",
    "                                       midpoint=0.0,\n",
    "                                       stop=1.0,\n",
    "                                       name='shifted')\n",
    "        ax = plt.matshow(myDF.corr(method=method), cmap=shifted_cmap, fignum=f.number)\n",
    "        plt.tick_params(labelsize=14)\n",
    "        cb = plt.colorbar()\n",
    "        cb.ax.tick_params(labelsize=14)\n",
    "        plt.title(title, fontsize=16);\n",
    "        plt.show()\n",
    "    \n",
    "    def plotGivenCorrMatrix(self, corrMatrix: pd.DataFrame, title: str, method: str = \"pearson\"):\n",
    "        f = plt.figure(figsize=(15, 12))\n",
    "        orig_cmap = matplotlib.cm.PuOr\n",
    "        shifted_cmap = self.shiftedColorMap(orig_cmap, \n",
    "                                       start=-1.0,\n",
    "                                       midpoint=0.0,\n",
    "                                       stop=1.0,\n",
    "                                       name='shifted')\n",
    "        ax = plt.matshow(corrMatrix, cmap=shifted_cmap, fignum=f.number)\n",
    "        plt.tick_params(labelsize=14)\n",
    "        cb = plt.colorbar()\n",
    "        cb.ax.tick_params(labelsize=14)\n",
    "        plt.title(title, fontsize=16);\n",
    "        plt.show()\n",
    "    \n",
    "    def plot2D(self, \n",
    "               gdpidData: pd.DataFrame, year: int,\n",
    "               xVar_base: str,\n",
    "               yVar_base: str,\n",
    "               ):\n",
    "\n",
    "        yrData = gdpidData.loc[gdpidData[\"year\"] == year].copy()\n",
    "        xVar = xVar_base + str(year)\n",
    "        yVar = yVar_base + str(year)\n",
    "        if yVar_base == \"mean_to_median_household_income_ratio\":\n",
    "            yVar = yVar_base\n",
    "        #     ax = gdpidData.plot.scatter (x=\"real_gdp_2012usd_\" + year, y=\"income_usd_\" + year, figsize=(10, 8))\n",
    "        ax = yrData.plot.scatter (x=xVar, \n",
    "                                  y=yVar, figsize=(10, 8))\n",
    "\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "        if yVar_base != \"mean_to_median_household_income_ratio\":\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.set_title(\"Personal Income and \" + xVar_base + \" for \" + str(year), fontsize=14)\n",
    "            ax.set_ylabel(\"Mean to Median Income Ratio\", fontsize=14)\n",
    "        else:\n",
    "            ax.set_title(\"Income Disparity and \" + xVar_base + \" for \" + str(year), fontsize=14)\n",
    "            ax.set_ylabel(\"Mean to Median Income Ratio\", fontsize=14)\n",
    "\n",
    "        ax.set_xlabel(xVar, fontsize=14)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def analyzeCorr4Migrations(self, \n",
    "                               tgt_correlated_features: pd.DataFrame, \n",
    "                               what: str = \"NETMIG\"):\n",
    "        myCorr = \\\n",
    "        tgt_correlated_features.loc[tgt_correlated_features.feature_2 == \\\n",
    "                                    what].copy().reset_index(drop=True)\n",
    "\n",
    "        print(\"\\n-------------------------------------------\")\n",
    "        print(what + \" into US counties is negatively correlated with:\\n\")\n",
    "        for ff in list(myCorr.sort_values(\"correlation\").loc[myCorr[\"correlation\"] < 0].feature_1):\n",
    "            print(ff)\n",
    "\n",
    "        print(\"\\n-------------------------------------------\")\n",
    "        print(what + \" into US counties is positively correlated with:\\n\")\n",
    "        for ff in list(myCorr.sort_values(\"correlation\").loc[myCorr[\"correlation\"] > 0].feature_1):\n",
    "            print(ff)\n",
    "\n",
    "        return myCorr.sort_values(\"correlation\").reset_index(drop=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    Details in \n",
    "    https://stackoverflow.com/questions/31909945/obtain-eigen-values-and-vectors-from-sklearn-pca/31941631#31941631\n",
    "    \n",
    "    Apply PCA; select the primary principal components:\n",
    "    (a) outliers in eigenvalues (default);\n",
    "    (b) PCs with eigenvalues greater than a given tolerance % of max eigenvalue; \n",
    "    (c) or  with the lowest frequency on the histogram.\n",
    "    \n",
    "    Note: the outlier-based selection will only work if we have more than 10-15 PCs.  \n",
    "    This method is sensitive to number of PCs.\n",
    "    \"\"\"\n",
    "    def applyPCA(self, \n",
    "                 gdpiData: pd.DataFrame,\n",
    "                 cols: List[str],\n",
    "                 n_comps: int,\n",
    "                 identify_outliers: bool = True,\n",
    "                 beta_outliers: float = 1.5,\n",
    "                 tolerance: float = -1.0,\n",
    "                 remove_most_frequent: bool = False,\n",
    "                 \n",
    "                 verbose: bool = False,\n",
    "                 showplots: bool = False) -> Tuple[pd.DataFrame, List[float]]:\n",
    "\n",
    "\n",
    "        data = myDF[cols]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\"\"We have {len(cols)} population-dynamics variables \"\"\"\n",
    "              f\"\"\"to use for modeling net migration into each county\"\"\")\n",
    "\n",
    "            print(f\"\"\"We are going to reduce it by identifying the\"\"\"\n",
    "                  f\"\"\"primary components.  We will start with {n_comps}\"\"\")\n",
    "        \n",
    "        \"\"\"Normalize by StDev:\"\"\"\n",
    "        data /= np.std(data, axis=0)\n",
    "\n",
    "        pcaMdl = decomposition.PCA(n_components=n_comps)\n",
    "        pcaMdl.fit(data)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Eigenvectors:\")\n",
    "            print(pcaMdl.components_)\n",
    "            print(\"Eigenvalues:\")\n",
    "            print(pcaMdl.explained_variance_)\n",
    "\n",
    "        eigenvalues = pcaMdl.explained_variance_\n",
    "        transformed = pcaMdl.transform(data)\n",
    "\n",
    "        for cc in range(n_comps):\n",
    "            myDF[\"pc_\" + str(cc)] = [transformed[ii][cc] for ii in range(len(transformed))]\n",
    "\n",
    "        \"\"\"Identify Outliers in Eigenvalues\"\"\"\n",
    "        if identify_outliers:\n",
    "            print(f\"\"\"Of these {n_comps}, we will select \"\"\"\n",
    "                  f\"\"\"the EigenValue outliers, to avoid overfitting the model\"\"\")\n",
    "            ax = plt.subplot()\n",
    "            ax.boxplot(eigenvalues, vert=False)\n",
    "            ax.set_title(\"Eigenvalues of the principal components\", fontsize=14)\n",
    "            plt.show()\n",
    "            \n",
    "            \"\"\"\n",
    "            Select primary components as outliers in Eigenvalues\n",
    "            \"\"\"\n",
    "            qrtls = np.percentile(eigenvalues, q=(25.0, 75.0))\n",
    "            qrtls\n",
    "            iqr = max(qrtls) - min(qrtls)\n",
    "            high_bound = max(qrtls) + beta_outliers * iqr\n",
    "            high_bound\n",
    "\n",
    "            primary_components = [ee for ee in eigenvalues if ee >= high_bound]\n",
    "            print(f\"\"\"In this case, primary components are ones \"\"\"\n",
    "                  f\"\"\"with eigenvalues >= {high_bound}\"\"\")\n",
    "        else:\n",
    "            primary_components = [ee for ee in eigenvalues if ee >= max(qrtls)]\n",
    "            print(f\"\"\"In this case, primary components are ones \"\"\"\n",
    "                  f\"\"\"with eigenvalues >= {max(qrtls)}\"\"\")\n",
    "             \n",
    "        print(f\"\"\"We have {len(primary_components)} primary principal components:\"\"\")\n",
    "        for ii in range(len(primary_components)):\n",
    "            print(f\"\"\"{ii}: {primary_components[ii]:.3f}\"\"\")\n",
    "            \n",
    "        if tolerance > 0:\n",
    "            maxPC = max(eigenvalues)\n",
    "            print(f\"\"\"Removing PCs with eigenvalues < {(100.0*tolerance): .3f}% of {maxPC}\"\"\")\n",
    "            primary_components = [pc for pc in eigenvalues if pc >= tolerance * maxPC]\n",
    "            \n",
    "        if remove_most_frequent:\n",
    "            ax = plt.subplot()\n",
    "            myHist = ax.hist(eigenvalues)\n",
    "            if verbose:\n",
    "                print(myHist[0])\n",
    "                print(myHist[1])\n",
    "            counts = list(myHist[0])\n",
    "            maxCountIndex = counts.index(max(counts))\n",
    "            maxCountEigenvalue = myHist[1][maxCountIndex]\n",
    "            \n",
    "            primary_components = [pp for pp in eigenvalues if pp > maxCountEigenvalue]\n",
    "            \n",
    "        return myDF, list(primary_components)\n",
    "    \n",
    "    \"\"\"\n",
    "    Apply linear regression\n",
    "    \"\"\"\n",
    "    def applyLinRegr(self, \n",
    "                     pcPopDF: pd.DataFrame, \n",
    "                     year: int,\n",
    "                     primary_components: List[float],\n",
    "                     verbose: bool = True,\n",
    "                     showplots: bool = True,\n",
    "                    ) -> pd.DataFrame:\n",
    "        print(year)\n",
    "\n",
    "        yVar = \"NETMIG\" + str(year)\n",
    "        frmla = yVar + \" ~ \"\n",
    "        frmla\n",
    "\n",
    "        rhs = \" + \".join([\"pc_\" + str(ii) for ii in range (len(primary_components))])\n",
    "        rhs\n",
    "\n",
    "        frmla += rhs\n",
    "        frmla\n",
    "        \n",
    "        linMdl = lm.OLS.from_formula(formula=frmla, data = pcPopDF)\n",
    "        res = linMdl.fit()\n",
    "\n",
    "        if verbose:\n",
    "            print(res.summary())\n",
    "        \n",
    "        pcPopDF[yVar + \"_LM\"] = res.predict()\n",
    "        \n",
    "        if showplots:\n",
    "            ax = pcPopDF.plot.scatter(x=yVar, \n",
    "                                 y=yVar + \"_LM\", \n",
    "                                 figsize=(10, 6))\n",
    "            ax.set_title(yVar + \" and linear regression prediction\",\n",
    "                         fontsize=16\n",
    "                        )\n",
    "            ax.set_xlabel(yVar, fontsize=14)\n",
    "            ax.set_ylabel(yVar + \" model prediction\", fontsize=14)\n",
    "            plt.show()\n",
    "            \n",
    "        return pcPopDF\n",
    "    \n",
    "    \"\"\"\n",
    "    Fit random forest regression to get the importance of each of the primary components\n",
    "    \"\"\"\n",
    "    def fitRFR(self, \n",
    "               pcPopDF: pd.DataFrame, \n",
    "               xVars: List[str] = [],\n",
    "               yVarBase: str = \"NETMIG\",\n",
    "               year: int = 2010,\n",
    "               ctv_cutoff: float = 0.055,\n",
    "               n_rfr_trees: int = 100,\n",
    "               verbose: bool = False,\n",
    "              ) -> Tuple[List[str], pd.DataFrame]:\n",
    "        \n",
    "        # create regressor object \n",
    "        regressor = RandomForestRegressor(n_estimators=n_rfr_trees, random_state = 0) \n",
    "\n",
    "        # fit the regressor with x and y data \n",
    "        if yVarBase is None or len(yVarBase) == 0:\n",
    "            yVarBase = \"NETMIG\"\n",
    "            \n",
    "        yVar = yVarBase + str(year)\n",
    "        \n",
    "        x = pcPopDF[xVars]\n",
    "        y = pcPopDF[yVar]\n",
    "        rfr = regressor.fit(x, y) \n",
    "    \n",
    "        pcPopDF[yVar + \"_rfr_predict\"] = regressor.predict(pcPopDF[xVars])\n",
    "        importances = list(rfr.feature_importances_)\n",
    "        importances\n",
    "\n",
    "        important_features = \\\n",
    "            [ii for ii in range(len(importances)) if importances[ii] > ctv_cutoff]\n",
    "\n",
    "        importantXs = [xVars[impfeat] for impfeat in important_features]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\"\"Feature Importances (contributions to variance):\"\"\")\n",
    "\n",
    "            \"\"\"sort xVars in order of importances\"\"\"\n",
    "            ctvDict = {} # Dict[str: int]\n",
    "            for ii in range(len(importances)):\n",
    "                ctvDict[xVars[ii]] = importances[ii]\n",
    "                \n",
    "            ctvlist = sorted(ctvDict.items(), key=lambda x: x[1], reverse=True)\n",
    "            for kk in ctvlist:\n",
    "                print(f\"\"\"{kk[0]}: {kk[1]: .3f}\"\"\")\n",
    "                \n",
    "            print(f\"\"\"Identified important features (CTV cutoff = {ctv_cutoff})\\n\"\"\")\n",
    "\n",
    "            \n",
    "            for kk in ctvlist:\n",
    "                if kk[0] in importantXs:\n",
    "                    print(f\"\"\"{kk[0]}: {kk[1]: .3f}\"\"\")\n",
    "                    \n",
    "            print(f\"\"\"\\nRFR R^2 with identified features: \"\"\"\n",
    "                  f\"\"\"{sum([importances[ii] for ii in important_features]): .3f}\"\"\")\n",
    "\n",
    "#         importantXs = [\"pc_\" + str(ii) for ii in important_features]\n",
    "        \n",
    "    \n",
    "        return [xVars[impfeat] for impfeat in important_features], pcPopDF\n",
    "    \n",
    "    def applyLinearRegression(self,\n",
    "                              pcPopDF: pd.DataFrame,\n",
    "                              importantXs: List[str],\n",
    "                              yVarBase: str = \"NETMIG\",\n",
    "                              year: int = 2010,\n",
    "                              verbose: bool = True,\n",
    "                              showplots: bool = True,\n",
    "                             ) -> pd.DataFrame:\n",
    "        \n",
    "        yVar = yVarBase + str(year)\n",
    "        frmla = yVar + \" ~ \"\n",
    "        print(frmla)\n",
    "\n",
    "        rhs = \" + \".join(importantXs)\n",
    "        print(rhs)\n",
    "        \n",
    "\n",
    "        frmla += rhs\n",
    "        print(frmla)\n",
    "\n",
    "        verbose=True\n",
    "        showplots=True\n",
    "\n",
    "        linMdl = lm.OLS.from_formula(formula=frmla, data = pcPopDF)\n",
    "        res = linMdl.fit()\n",
    "\n",
    "        if verbose:\n",
    "            print(res.summary())\n",
    "\n",
    "        pcPopDF[yVar + \"_LM\"] = res.predict()\n",
    "\n",
    "        if showplots:\n",
    "            ax = pcPopDF.plot.scatter(x=yVar, \n",
    "                                 y=yVar + \"_LM\", \n",
    "                                 figsize=(10, 6))\n",
    "            ax.set_title(yVar + \" and linear regression prediction\",\n",
    "                         fontsize=16\n",
    "                        )\n",
    "            ax.set_xlabel(yVar, fontsize=14)\n",
    "            ax.set_ylabel(yVar + \" model prediction\", fontsize=14)\n",
    "            plt.show()\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
