{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import dates\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn. model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "\n",
    "class tweetSentiment:\n",
    "    \n",
    "    def __init__(self, rawDir: str = './../meltwater/final_query/all_topics__',\n",
    "                 region: str = 'bay_area'):\n",
    "        self.mRegion = region\n",
    "        self.mDir = rawDir + self.mRegion + \"/\"\n",
    "        self.mColorDict = {'Negative':'red', \n",
    "                           'Neutral':'darkkhaki', \n",
    "                           'Positive':'royalblue', \n",
    "                           'NotRated':'darkcyan'}\n",
    "        \n",
    "    def getData(self):\n",
    "        \n",
    "        file_in = self.mDir.replace(self.mRegion + '/',  self.mRegion + '.csv')\n",
    "        \n",
    "        print(f\"Reading data from {file_in}\")\n",
    "        allTweetsDF = pd.read_csv(file_in, low_memory=False)\n",
    "        print(f\"\"\"Got all tweets data for {REGION} \"\"\"\n",
    "              f\"\"\"({len(allTweetsDF)} rows) from {file_in}\"\"\")\n",
    "        \n",
    "        dfS = self._prepTweetsDF4Analysis(allTweetsDF)\n",
    "        return dfS\n",
    "\n",
    "    def _prepTweetsDF4Analysis(self, allTweetsDF: pd.DataFrame):\n",
    "        \"\"\"Get the starting date of each week\"\"\"\n",
    "        wkof = pd.DataFrame(allTweetsDF.groupby(['year_week']).min()['date']).reset_index(drop=False, \n",
    "                                                                                          inplace=False)\n",
    "        wkof.rename(columns={'date': 'week_of'}, inplace=True)\n",
    "        wkof\n",
    "\n",
    "        df = allTweetsDF.merge(wkof)\n",
    "        df['sentiment'] = df.sentiment.str.replace(' ', '')\n",
    "\n",
    "        \"\"\"Add one-hot-encoded sentiments into separate columns for later analysis\"\"\"\n",
    "        s = pd.get_dummies(df.sentiment, prefix='sentiment')\n",
    "        dfS = pd.concat([df, s], axis=0, sort=False)\n",
    "        dfS.drop_duplicates(inplace=True)\n",
    "\n",
    "        \"\"\"Identify retweets, quotes, shares.  Add original tweets\"\"\"\n",
    "        dfS['is_retweet'] = dfS.hit_sentence.str.startswith('RT @')\n",
    "        dfS['is_quote'] = dfS.hit_sentence.str.startswith('QT @')\n",
    "        dfS['is_share'] = dfS.is_retweet | dfS.is_quote\n",
    "        dfS['is_url'] = dfS.hit_sentence.str.contains('http')\n",
    "        dfS['orig_tweet'] = dfS.hit_sentence.str.replace('RT @', '').str.replace('QT @', '')\n",
    "        dfS.head()\n",
    "\n",
    "        \"\"\"Clean up and finalize\"\"\"\n",
    "        dfS.dropna(inplace=True, subset=['hit_sentence'])\n",
    "        dfS.reset_index(inplace=True, drop=True)\n",
    "        dfS.head(2)\n",
    "\n",
    "        return dfS\n",
    "\n",
    "    \"\"\"Get primary weekly stats on sentiment and plot them\"\"\"\n",
    "    def analyzeSharedTweetsSentiment(self, \n",
    "                                     dfS: pd.DataFrame, \n",
    "                                     showplots: bool,\n",
    "                                     includeNotRated: bool = False\n",
    "                                    ):\n",
    "\n",
    "        \"\"\"Identify shared tweets\"\"\"\n",
    "        shares = dfS.is_share.sum()\n",
    "        totals = len(dfS)\n",
    "        frac_shares = float(shares) / totals\n",
    "        unique_key_phrases = dfS.key_phrases.unique()\n",
    "        \n",
    "        print(f\"We have {totals} tweets, of which {shares} ({frac_shares:.3f}) are retweets or quotes\")\n",
    "        print(f\"We have {len(unique_key_phrases)} unique key phrases\")\n",
    "\n",
    "        \"\"\"Get Total Number of Tweets in each sentiment for each week\"\"\"\n",
    "        dfS_wk = pd.DataFrame(dfS.groupby(['week_of']).count()['sentiment'])\n",
    "        dfS_wk.rename(columns={'sentiment': 'total'}, inplace=True)\n",
    "        dfS_wk.reset_index(drop=False, inplace=True)\n",
    "        dfS_wk.head()\n",
    "\n",
    "        \"\"\"Get Number of Shared Tweets in each (week_of, sentiment) tuple\"\"\"\n",
    "        dfS_wk_share = pd.DataFrame(dfS.groupby(['week_of', 'sentiment']).sum()['is_share'])\n",
    "        dfS_wk_share.rename(columns={'is_share': 'shared'}, inplace=True)\n",
    "        dfS_wk_share.reset_index(drop=False, inplace=True)\n",
    "        dfS_wk_share.head()\n",
    "\n",
    "        \"\"\"Join dfS_wk with dfS_wk_share\"\"\"\n",
    "        dfSwk = dfS_wk.merge(dfS_wk_share)\n",
    "        dfSwk['shared_frac_total'] = dfSwk.shared.astype(float) / dfSwk.total\n",
    "        dfSwk.head()\n",
    "        \n",
    "        if not includeNotRated:\n",
    "            dfSwk = dfSwk.loc[dfSwk.sentiment != 'NotRated'].copy().reset_index(drop=True, \n",
    "                                                                                 inplace=False)\n",
    "            \n",
    "        weekly_aggr_wide = dfSwk.pivot_table(index='week_of',\n",
    "                                             columns='sentiment', \n",
    "                                             values='shared_frac_total').reset_index(drop=False)\n",
    "        #         print(weekly_aggr_wide.columns)\n",
    "        weekly_aggr_wide.head()\n",
    "\n",
    "        if showplots:\n",
    "            weekly_aggr_wide.plot(\n",
    "                      x='week_of',\n",
    "                      linewidth=3.0,\n",
    "                      figsize=(16, 8),\n",
    "                      color=[self.mColorDict.get(x, '#333333')\n",
    "                             for x in weekly_aggr_wide.iloc[:, 1:].columns])\n",
    "            plt.ylabel('Fraction of Total Shared Tweets', fontsize=18)\n",
    "            plt.xlabel('Week Start Date', fontsize=18)\n",
    "            plt.yticks(fontsize=14)\n",
    "            plt.xticks(list(range(len(weekly_aggr_wide.week_of))), \n",
    "                            weekly_aggr_wide.week_of, \n",
    "                            rotation=90, \n",
    "                            fontsize=13)\n",
    "            plt.legend(fontsize=18)\n",
    "            plt.title(f\"Dynamics of Sentiment in Shared Tweets for {self.mRegion}\", fontsize=22)\n",
    "            plt.show()\n",
    "            \n",
    "    \"\"\"Get primary weekly stats on sentiment and plot them\"\"\"\n",
    "    def analyzeSentiment(self,\n",
    "                         dfS: pd.DataFrame,\n",
    "                         showplots: bool,\n",
    "                         includeNotRated: bool = False,\n",
    "                         tweets_or_news: str = 'Tweets'\n",
    "                        ):\n",
    "\n",
    "        \"\"\"Get weekly totals\"\"\"\n",
    "        weekly_totals = ((dfS.groupby(['week_of'])).count()['year_week']).reset_index(drop=False)\n",
    "        weekly_totals.rename(columns={'year_week': 'total'}, inplace=True)\n",
    "\n",
    "        \"\"\"Get weekly totals for each sentiment\"\"\"\n",
    "        weekly_s_totals = ((dfS.groupby(['week_of', 'sentiment'])).count()['year_week']).reset_index(drop=False)\n",
    "        weekly_s_totals.rename(columns={'year_week': 'sentiment_total'}, inplace=True)\n",
    "        weekly_s_totals.head()\n",
    "\n",
    "        \"\"\"Join (merge) the two and compute weekly sentiment fractions\"\"\"\n",
    "        weekly_aggr = weekly_totals.merge(weekly_s_totals)\n",
    "        weekly_aggr['frac_sentiment'] = weekly_aggr.sentiment_total.astype(float) / weekly_aggr.total\n",
    "        \n",
    "        if not includeNotRated:\n",
    "            weekly_aggr = \\\n",
    "                weekly_aggr.loc[weekly_aggr.sentiment != 'NotRated'].copy().reset_index(drop=True,\n",
    "                                                                                        inplace=False)\n",
    "\n",
    "        weekly_aggr_wide = weekly_aggr.pivot_table(index='week_of',\n",
    "                                                   columns='sentiment', \n",
    "                                                   values='frac_sentiment').reset_index(drop=False)\n",
    "        #         print(weekly_aggr_wide.columns)\n",
    "        weekly_aggr_wide.head()\n",
    "\n",
    "        if showplots:\n",
    "            weekly_aggr_wide.plot(\n",
    "                      x='week_of',\n",
    "                      linewidth=3.0,\n",
    "                      figsize=(16, 8),\n",
    "                      color=[self.mColorDict.get(x, '#333333')\n",
    "                             for x in weekly_aggr_wide.iloc[:, 1:].columns])\n",
    "            plt.ylabel('Fraction of Total Tweets', fontsize=18)\n",
    "            plt.xlabel('Week Start Date', fontsize=18)\n",
    "            plt.yticks(fontsize=14)\n",
    "            plt.xticks(list(range(len(weekly_aggr_wide.week_of))), \n",
    "                            weekly_aggr_wide.week_of, \n",
    "                            rotation=90, \n",
    "                            fontsize=13)\n",
    "            plt.legend(fontsize=18)\n",
    "            plt.title(f\"Dynamics of Sentiment in All {tweets_or_news} for {self.mRegion}\", fontsize=22)\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
